{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T11:45:44.861168Z",
     "start_time": "2025-10-30T11:45:29.299449Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "Data=pd.read_csv('data.csv')\n",
    "#Replacing the Values in the DataFrame\n",
    "print(Data.shape)\n",
    "# Data.drop(columns=['id','Unnamed: 32'],axis=1,inplace=True)\n",
    "# Data.drop(columns=['id','Unnamed: 32'],axis=1,inplace=True)\n",
    "# Data.drop(columns=['id','Unnamed: 32'],axis=1,inplace=True)\n",
    "Data.drop(columns=['id','Unnamed: 32'],axis=1,inplace=True)\n",
    "Data.columns\n"
   ],
   "id": "bec690189ac500cc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 33)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean',\n",
       "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
       "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
       "       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
       "       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
       "       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
       "       'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
       "       'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
       "       'symmetry_worst', 'fractal_dimension_worst'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T11:45:45.066709Z",
     "start_time": "2025-10-30T11:45:45.035577Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# X_Train,X_Test,y_Train,y_Test=train_test_split(Data.iloc[:,1:],Data.iloc[:,0],test_size=0.2,random_state=42)\n",
    "#Spliting the Data into the two sets\n",
    "X_Train,X_Test,y_Train,y_Test=train_test_split(Data.iloc[:,1:],Data.iloc[:,0],test_size=0.2,random_state=42)\n",
    "X_Train.shape"
   ],
   "id": "3cd8c5648ec2f944",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(455, 30)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "StandardScaler",
   "id": "4e0c24f4c1aa5071"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T11:45:45.334118Z",
     "start_time": "2025-10-30T11:45:45.285352Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#We have Created Instance of the Standard Scaler\n",
    "''''Scaler=StandardScaler()\n",
    "''''X_Train=Scaler.fit_transform(X_Train)'''\n",
    "Scaler=StandardScaler()\n",
    "X_Train=Scaler.fit_transform(X_Train)\n",
    "X_Test=Scaler.transform(X_Test)\n",
    "Scaler=StandardScaler()\n",
    "X_Train=Scaler.fit_transform(X_Train)\n",
    "X_Test=Scaler.transform(X_Test)\n",
    "X_Test.shape"
   ],
   "id": "65c38474aef35018",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114, 30)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "LabelEncoder",
   "id": "ad3cef81e79716fc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T11:45:45.485619Z",
     "start_time": "2025-10-30T11:45:45.463050Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# #Here We have to create the Instance of the Label Encoder\n",
    "# Encoder=LabelEncoder()\n",
    "# y_Train=Encoder.fit_transform(y_Train)\n",
    "# y_Test=Encoder.transform(y_Test)\n",
    "# y_Test\n",
    "Encoder=LabelEncoder()\n",
    "y_Train=Encoder.fit_transform(y_Train)\n",
    "y_Test=Encoder.transform(y_Test)\n",
    "y_Test"
   ],
   "id": "dad2620d339c88b3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0,\n",
       "       1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 0, 0, 1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "NOW Converting the Numpy Array to Tensor",
   "id": "7dd7a4474781961c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T11:45:45.629015Z",
     "start_time": "2025-10-30T11:45:45.611908Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# X_Train_Tensor=torch.from_numpy(X_Train)\n",
    "# X_Test_Tensor=torch.from_numpy(X_Test)\n",
    "# y_Train_Tensor=torch.from_numpy(y_Train)\n",
    "# y_Test_Tensor=torch.from_numpy(y_Test)\n",
    "X_Train_Tensor=torch.from_numpy(X_Train)\n",
    "X_Test_Tensor=torch.from_numpy(X_Test)\n",
    "y_Train_Tensor=torch.from_numpy(y_Train)\n",
    "y_Test_Tensor=torch.from_numpy(y_Test)\n",
    "print(type(X_Train_Tensor))\n",
    "print(type(X_Train))"
   ],
   "id": "5f44934d02b4bc03",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Defining Model",
   "id": "2c08d99084f92f99"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T11:45:45.822217Z",
     "start_time": "2025-10-30T11:45:45.804495Z"
    }
   },
   "cell_type": "markdown",
   "source": [
    "class SampleNN:\n",
    "    def __init__(self,x):\n",
    "        self.weights=torch.rand(x.shape[1],1,requires_grad=True,dtype=torch.float32)\n",
    "        self.bias=torch.zeros(1,dtype=torch.float32,requires_grad=True)\n",
    "    def forward(self,X):\n",
    "        z=torch.matmul(X,self.weights)\n",
    "        y_pred=torch.sigmoid(z)\n",
    "        return y_pred\n",
    "    def Loss(self,y_pred,y):\n",
    "        epsilon=1e-7\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "d488e9e0d113c1a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2ea3fb57ffd29c1a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
