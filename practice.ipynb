{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T07:18:21.387598Z",
     "start_time": "2025-10-29T07:18:21.345181Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "Data=pd.read_csv('data.csv')\n",
    "#Replacing the Values in the DataFrame\n",
    "print(Data.shape)\n",
    "# Data.drop(columns=['id','Unnamed: 32'],axis=1,inplace=True)\n",
    "# Data.drop(columns=['id','Unnamed: 32'],axis=1,inplace=True)\n",
    "# Data.drop(columns=['id','Unnamed: 32'],axis=1,inplace=True)\n",
    "Data.drop(columns=['id','Unnamed: 32'],axis=1,inplace=True)\n",
    "Data.columns\n"
   ],
   "id": "bec690189ac500cc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 33)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean',\n",
       "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
       "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
       "       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
       "       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
       "       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
       "       'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
       "       'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
       "       'symmetry_worst', 'fractal_dimension_worst'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T07:18:21.563330Z",
     "start_time": "2025-10-29T07:18:21.538913Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# X_Train,X_Test,y_Train,y_Test=train_test_split(Data.iloc[:,1:],Data.iloc[:,0],test_size=0.2,random_state=42)\n",
    "#Spliting the Data into the two sets\n",
    "X_Train,X_Test,y_Train,y_Test=train_test_split(Data.iloc[:,1:],Data.iloc[:,0],test_size=0.2,random_state=42)\n",
    "X_Train.shape"
   ],
   "id": "3cd8c5648ec2f944",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(455, 30)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 54
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "StandardScaler",
   "id": "4e0c24f4c1aa5071"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T07:18:21.690152Z",
     "start_time": "2025-10-29T07:18:21.646615Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#We have Created Instance of the Standard Scaler\n",
    "''''Scaler=StandardScaler()\n",
    "''''X_Train=Scaler.fit_transform(X_Train)'''\n",
    "Scaler=StandardScaler()\n",
    "X_Train=Scaler.fit_transform(X_Train)\n",
    "X_Test=Scaler.transform(X_Test)\n",
    "Scaler=StandardScaler()\n",
    "X_Train=Scaler.fit_transform(X_Train)\n",
    "X_Test=Scaler.transform(X_Test)\n",
    "X_Test.shape"
   ],
   "id": "65c38474aef35018",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114, 30)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 55
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "LabelEncoder",
   "id": "ad3cef81e79716fc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T07:29:25.779181Z",
     "start_time": "2025-10-29T07:29:25.763155Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# #Here We have to create the Instance of the Label Encoder\n",
    "# Encoder=LabelEncoder()\n",
    "# y_Train=Encoder.fit_transform(y_Train)\n",
    "# y_Test=Encoder.transform(y_Test)\n",
    "# y_Test\n",
    "Encoder=LabelEncoder()\n",
    "y_Train=Encoder.fit_transform(y_Train)\n",
    "y_Test=Encoder.transform(y_Test)\n",
    "y_Test"
   ],
   "id": "dad2620d339c88b3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0,\n",
       "       1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 0, 0, 1])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 61
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "NOW Converting the Numpy Array to Tensor",
   "id": "7dd7a4474781961c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T07:33:06.832699Z",
     "start_time": "2025-10-29T07:33:06.818748Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# X_Train_Tensor=torch.from_numpy(X_Train)\n",
    "# X_Test_Tensor=torch.from_numpy(X_Test)\n",
    "# y_Train_Tensor=torch.from_numpy(y_Train)\n",
    "# y_Test_Tensor=torch.from_numpy(y_Test)\n",
    "X_Train_Tensor=torch.from_numpy(X_Train)\n",
    "X_Test_Tensor=torch.from_numpy(X_Test)\n",
    "y_Train_Tensor=torch.from_numpy(y_Train)\n",
    "y_Test_Tensor=torch.from_numpy(y_Test)\n",
    "print(type(X_Train_Tensor))\n",
    "print(type(X_Train))"
   ],
   "id": "5f44934d02b4bc03",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "execution_count": 72
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T08:39:52.811795Z",
     "start_time": "2025-10-29T08:39:52.790155Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# import torch\n",
    "# a=torch.tensor([1,2,3,4.])\n",
    "# a.add_(10)\n",
    "# a.mul_(2)\n",
    "# a.sub_(1)\n",
    "# print(a.div_(3.5))\n",
    "# print(a)\n",
    "import torch\n",
    "a=torch.tensor([1,2,3,4.])\n",
    "print(\"Actual Tensor\",a)\n",
    "a.add_(10)\n",
    "print(\"Adding 10 to All  the Elements \",a)\n",
    "a.mul_(2)\n",
    "print(\"After Multiplying the 2 to All Elements to Tensor\",a)\n",
    "a.div_(2.)\n",
    "print(\"Division to all Elements\",a)"
   ],
   "id": "71372e5da69f4ed1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Tensor tensor([1., 2., 3., 4.])\n",
      "Adding 10 to All  the Elements  tensor([11., 12., 13., 14.])\n",
      "After Multiplying the 2 to All Elements to Tensor tensor([22., 24., 26., 28.])\n",
      "Division to all Elements tensor([11., 12., 13., 14.])\n"
     ]
    }
   ],
   "execution_count": 9
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
